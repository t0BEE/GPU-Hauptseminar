% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
\documentclass[a4paper,12pt]{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\makeindex

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}      % Code-Page latin 1
\usepackage[T1]{fontenc}
\usepackage{listings}
% Nur eine der beiden folgenden Zeilen einbinden!
% siehe Abschnitt Bilder
%\usepackage{graphicx}       % Bilder einbinden, Version fuer normales latex
\usepackage[pdftex]{graphicx}       % Bilder einbinden, Version fuer pdflatex

% mit Hyperrefs
\usepackage[pdftex, plainpages=false,hypertexnames=true,pdfnewwindow=true,backref=true,colorlinks=true,citecolor=blue,linkcolor=black,urlcolor=blue,filecolor=blue]{hyperref}%
% weitere Packages
\usepackage{ifthen}                 % Zum Auskommentieren von Textteilen
\usepackage{amssymb}                % Mathematische Buchstaben
\usepackage{amsmath}                % Verbesserter Formelsatz
\usepackage{booktabs}               % schönere Tabellen
\usepackage{color}
\usepackage{hyperref}
 \hypersetup{urlcolor=black,citecolor=black}
\usepackage{dsfont}
%\newtheorem{definition}{Definition}
\usepackage{doc}

% Seitenformat ===============================================================
\hoffset=-1.25truecm
\setlength{\topmargin}{0.0cm}
\setlength{\textheight}{23.0cm}
\setlength{\footskip}{1.5cm}
\setlength{\textwidth}{15.4cm}
\setlength{\evensidemargin}{1.5cm}
\setlength{\oddsidemargin}{1.5cm}
\setlength{\parskip}{1ex}
\setlength{\parindent}{0pt}
\setlength{\marginparwidth}{1.4cm}
\setlength{\marginparsep}{1mm}

\pagestyle{plain}

% LstListing-Format ==========================================================
\lstdefinestyle{cpp}{
  language=C++,
  basicstyle=\small\ttfamily,
  frame=tb,
  xleftmargin=\parindent,
  keywordstyle=\color{blue},
  stringstyle=\color{red},
  commentstyle=\color{green},
  morecomment=[l][\color{magenta}]{\#},
  framexleftmargin=5pt,
  framexrightmargin=5pt,
  framextopmargin=5pt,
  framexbottommargin=5pt,
  literate={~}{$\sim$}1
}

% Makro-Definitionen ==========================================================
% Zahlenbereiche -------------------------------------------------------------
\newcommand{\N}{{\mathbb{N}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\C}{{\mathbb{C}}}
\newcommand{\Z}{{\mathbb{Z}}}
\newcommand{\Q}{{\mathbb{Q}}}

%
\def\myverzeichnis{.}

\numberwithin{equation}{section}
% Bild -----------------------------------------------------------------------
% #1 Filename;  #2 Label;  #3 Bildunterschrift;  #4 Kurzform
\newcommand{\bild}[4]{
  \begin{figure}[htbp]
    \begin{center}
      \includegraphics{#1}
      \caption[#4]{#3}
      \label{#2}
    \end{center}
  \end{figure}
}

% Bildbreite -----------------------------------------------------------------
% #1 Filename;  #2 Breite;  #3 Label;  #4 Bildunterschrift;  #5 Kurzform
\newcommand{\bildbreite}[5]{
  \begin{figure}[htbp]
    \begin{center}
      \includegraphics[width=#2]{#1}
      \caption[#5]{#4}
      \label{#3}
    \end{center}
  \end{figure}
}


% ============================================================================
\begin{document}

% =========== Das war der Vorspann, jetzt geht's los! ========================

% ============================================================================
% =============  AB HIER DARF UND SOLL GETIPPT WERDEN ========================
% ============================================================================

\author{Tobias Schiffmann}
\index{Viel Schreiber}

% Das Institut wird fuer den Betreuer missbraucht ...
\institute{{\bf Betreuer:} Gregor Daiß}
\authorrunning{Viel Schreiber}
\title{SIMT/GPGPU - CUDA \& OpenCL}

\maketitle

\thispagestyle{empty}

\begin{abstract}
Ein schöner Abstract. Das ist einfach die Kurzzusammenfassung.
\end{abstract}


\section{Motivation}
  1 entworfen für Grafikanwendungen mit sehr großen Datenmengen\\
    --> haben sich relativ unabhängig von CPUs entwickelt\\
    --> im Grafikbereich: hohes Potential an Datenparallelität! --> keine Abhängigkeiten\\
  1 sehr hoher FP-Operation durchsatz, verteilt auf große Anzahl Threads\\
  4 interessant in anderen Anwendungsgebieten --> General Purpose GPU\\
    
%---------------------------------------------------------------------------------
    
\section{Difference between CPU and GPU}
\subsection{GPU Architecture}
    - Function units / architecture picture\\
      1 multi-threaded SIMD-Prozessoren (NVIDEA: Streaming Multiprocessors [SMX]), können als unabhängige MIMD-Kerne betrachtet werden\\
      1 jeder SIMD Prozessor hat mehrere SIMD-Funktionseinheiten( jede hat Int und FP - Einheit)\\
	  3 Turing architecture\\
	  - Figure \ref{fig:turingOverall} evtl in appendix\\
	  \bildbreite{figures/Turing_architecture.JPG}{\textwidth}{fig:turingOverall}{8 Turing Architecture TU106 (RTX2070)}{}
	  - Figure \ref{fig:smArch}
	  \bildbreite{figures/SM_arch.jpg}{9cm}{fig:smArch}{8 SM Architecture}{}
	  8 2 SMs per TPC (Texture Processing Cluster)
	  8 SM is divided into 4 processing blocks
	    - each with 16 FP32 Cores, 16 INT32 Cores, two Tensor Cores, one warp scheduler, and one dispatch unit
	    - each block includes a new L0 instruction cache and a 64 KB register file
	    - all share a combined 96 KB L1 data cache/shared memory.

	  3 Tensor Core as special Deep Learning Accelerator
	    - Matrix-Accumulate functions --> essential part in deep learning
	  3 RTCore accelerates ray tracing
	    - Accelerate ray probing and move it to other function units
	    - SM can do other tasks meanwhile
	  
	  
    - memory hierarchy\\
      1 + 4 verschiedene Speichertypen\\
        - global memory(host-RW, Device-RW)\\
        - constant memory (host-RW, device-R)\\
        - register(nur thread kann drauf zu greifen) and shared memory(alle threads eines Blocks) (kurze Zugriffszeit)\\
        - Figure \ref{fig:memorga}
    \bild{figures/speicheroragnisation.jpg}{fig:memorga}{1 Memory Organization}{}
        
\subsection{Latency Hiding}
  
\subsection{Thread Scheduling}
        - passiert nicht auf der Ebene einzelner Threads, sondern "Warps" --> mehrere Threads eines Blocks (aufsteigende threadIDx) zusammengefasst\\
        - eine Instruktion nach der anderen für alle Threads eines Warps ausführen --> \textbf{SIMT}\\
        --> Instruktionen auf verschiedenen Kontrollflüssen, wenn gleich, dann kann schnell sein\\
         	Falls, unterschiedlich SIMT nur beschränkt möglich, kann sich auch bei if-else aufteilen\\
         
\subsection{Performance}
  - Examples for each in Peak Performance GFLOPS\\
    --> white papers of the products

%---------------------------------------------------------------------------------

\section{CUDA - A GPU Programming Model}
      1 NVIDIA as vendor\\
      1 program separation in host program (CPU [IO + User]) and device program (GPU)\\
      1 device program = kernel-functions/kernels\\
	  1 interaction: host program copies data in GPU memory and calls device function\\
	  1 a program starts via a host program until kernel function is called -> then both run in parallel till synchronization\\
		- Call creates CUDA- Threads (summarized as Grid)\\
	  1+4 kernel call contains \textit{execution configuration}\\
	    --> specifies the organization of the generated Threads in the Grid of the kernel function\\
	  	  - unterteile Threads des Grids in Blöcke von Threads (3-dim, blockIDx.xyz)\\
	  	  - Blöcke sind in threads aufgeteilt (3-dim, threadIDx.xyz)\\
	   --> jeder einzelne Thread des Grids kann aufgerufen werden eine Kernel-Funktion auszuführen\\
          - um Threads zu synchronisieren gibt es synchronisationsfunktionen nur innerhalb eines Blocks\\
          
  --> Example Implementation: Matrix - Matrix Multiplication


%---------------------------------------------------------------------------------
 
\section{OpenCL - A Multipurpose Programming Model}
  --> Differences to CUDA\\
  - Terminology\\
      1 Work-Items (CUDA-Threads) < Work-Groups < global NDRanges (Grid)\\
  - Basic information\\
      1 multiple partners (including NVIDIA)\\
      1 standardized programming model\\
      1 heterogeneous platform which needs explicit specification (Context)\\
        --> can also be used for FPGAs\\
        --> more complex than CUDA, but provides more diversity in HW\\
      


%---------------------------------------------------------------------------------

\section{Programming Optimization Techniques}
  - increase Occupancy\\
  - increase latency\\
  - problems / concerns (warp divergence)\\


%---------------------------------------------------------------------------------

\section{Conclusion and Discussion}

      


\begin{enumerate}
\item \cite{Rauber.2012} (1)
\item \cite{Lindholm.2008} (2)
\item \cite{Burgess.2020} (3)
\item \cite{Huang.2008} (4)
\item \cite{Bialas.2016} (5)
\item \cite{Khronos.2019} (6)
\item \cite{Wang.2019} (7)
\item \cite{NVIDIA.2018} (8)
\end{enumerate}





% Literaturverzeichnis ------------------------------------------------
\newpage
\bibliographystyle{alphadinLinkLocal}
\bibliography{literatur}

%\iffalse
\end{document}
%\fi
